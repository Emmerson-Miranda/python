# Introduction

Simple example that describe an image (my public picture) using [LLaVA](https://llava-vl.github.io/) LLM.

Original example: https://ollama.com/blog/vision-models

## Run

```bash
make run
```

The output is the description of my public picture.
```text
The image shows a man smiling at the camera. 
He has short dark hair and is wearing a black shirt with what appears to be an identification badge around his neck, 
suggesting he may be attending an event or conference where such badges are typically used for access control. 
The background of the photo is slightly blurred but seems to be an indoor setting with artificial lighting. 
His expression conveys friendliness and approachability.
```

Each run can give you similar results. This is after second run.
```text
The image shows a person smiling at the camera. 
The individual appears to be middle-aged, with short dark hair and is wearing what looks like a lanyard around their neck, 
which often indicates an ID card or event pass for work or an event. 
The person's attire consists of a dark top. 
In the background, there are elements that suggest an indoor setting with some plants, 
indicating it could be a corporate office space or a similar environment. 
There is no visible text in the image to provide additional context or information.
```
